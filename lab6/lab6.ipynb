{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "PORT = \"9200\"\n",
    "URL = \"http://localhost:\" + PORT + \"/\"\n",
    "\n",
    "def parse_analysis(string):\n",
    "    split_input = [x.strip() for x in string.split(\"\\t\") if x != \"\"]\n",
    "    \n",
    "    if len(split_input) != 3:\n",
    "        return ()\n",
    "    \n",
    "    base, form_explicit, _disamb = split_input\n",
    "    form = form_explicit.split(\":\")[0]\n",
    "    \n",
    "    return (base, form)\n",
    "\n",
    "def analyze(string):\n",
    "    content = requests.post(URL, data=string.encode('utf-8')).text\n",
    "    analyzed_words = [parse_analysis(analysis) for analysis in content.split(\"\\n\")[1::2] if analysis != \"\"]\n",
    "    \n",
    "    return [analysis for analysis in analyzed_words if analysis != ()]\n",
    "    \n",
    "def is_valid_unigram(unigram):\n",
    "    word, analysis = unigram\n",
    "    return analysis != \"interp\" and not analysis.startswith(\"num\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ala', 'subst'), ('mieć', 'fin'), ('kot', 'subst')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze(\"ala ma kota\\n\\n\\n\\n12     123.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LIST = 'files.p'\n",
    "DATA_DIR = \"/run/media/maciej/Nowy/data/json/\"\n",
    "CHOSEN_YEAR = \"2011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "judgment_types = {\n",
    "    \"I\":  \"A?C.*\",\n",
    "    \"II\": \"A?U.*\",\n",
    "    \"III\": \"A?K.*\",\n",
    "    \"IV\": \"G.*\",\n",
    "    \"V\": \"A?P.*\",\n",
    "    \"VI\": \"R.*\",\n",
    "    \"VII\": \"W.*\",\n",
    "    \"VIII\": \"Am.*\",\n",
    "}\n",
    "\n",
    "def get_judgment_type(number):\n",
    "    for key, value in judgment_types.items():\n",
    "        if re.search(value, number):\n",
    "            print(\"Found a match for {}\".format(number))\n",
    "            return key\n",
    "    print(\"Did not match for {}\".format(\n",
    "        number\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:01<00:00, 53.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3791 judgments from common and supreme courts\n",
      "24 of them have explanation section\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json, pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import regex\n",
    "from tqdm import tqdm\n",
    "\n",
    "word_pattern = \"\\p{Letter}+\"\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    total_judgments = []\n",
    "    files = pickle.load(open(FILE_LIST, 'rb'))\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        if file.startswith(\"judgment\"):\n",
    "            file_path = os.path.join(DATA_DIR, file)\n",
    "\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                judgments = [\n",
    "                    (x[\"textContent\"], x[\"courtCases\"][0][\"caseNumber\"]) for x in data[\"items\"] \n",
    "                    if x[\"judgmentDate\"].startswith(CHOSEN_YEAR) and x[\"courtType\"] in (\"COMMON\", \"SUPREME\")\n",
    "                ]\n",
    "                \n",
    "            total_judgments += judgments\n",
    "    \n",
    "    print(\"Found {} judgments from common and supreme courts\".format(len(total_judgments)))\n",
    "    \n",
    "    judgments_with_explanations = []    \n",
    "    for judgment, _case_num in total_judgments:        \n",
    "        match = regex.search(\"uzasadnienie:\", judgment, regex.IGNORECASE)        \n",
    "        if match:\n",
    "            judgments_with_explanations.append((judgment[match.end():], _case_num))\n",
    "            \n",
    "    print(\"{} of them have explanation section\".format(len(judgments_with_explanations)))\n",
    "    \n",
    "    analyzed_judgments = defaultdict(lambda: [])\n",
    "    raw_judgments = defaultdict(lambda: [])\n",
    "    \n",
    "#     for judgment, case_number in tqdm(judgments_with_explanations):\n",
    "        \n",
    "#         judgment = regex.sub(\"<.*?>\", \"\", judgment)\n",
    "#         judgment = regex.sub(\"-\\n(\\p{Letter}+)\", r\"\\1\", judgment)\n",
    "#         judgment = judgment.lower()\n",
    "\n",
    "#         judgment_type = get_judgment_type(case_number)\n",
    "\n",
    "#         raw_judgments[judgment_type].append(judgment)\n",
    "#         analyzed_judgments[judgment_type].append(analyze(judgment))\n",
    "        \n",
    "    \n",
    "    return analyzed_judgments, raw_judgments\n",
    "\n",
    "analyzed_judgments, raw_judgments = load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
