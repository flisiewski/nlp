{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "PORT = \"9200\"\n",
    "URL = \"http://localhost:\" + PORT + \"/\"\n",
    "\n",
    "def parse_analysis(string):\n",
    "    split_input = [x.strip() for x in string.split(\"\\t\") if x != \"\"]\n",
    "    if len(split_input) != 3:\n",
    "        return ()\n",
    "    \n",
    "    base, form_explicit, _disamb = split_input\n",
    "    form = form_explicit.split(\":\")[0]\n",
    "    \n",
    "    return (base, form)\n",
    "\n",
    "def analyze(string):\n",
    "    content = requests.post(URL, data=string.encode('utf-8')).text\n",
    "    analyzed_words = [parse_analysis(analysis) for analysis in content.split(\"\\n\")[1::2] if analysis != \"\"]\n",
    "    \n",
    "    return [analysis for analysis in analyzed_words if analysis != ()]\n",
    "    \n",
    "def is_valid_unigram(unigram):\n",
    "    word, analysis = unigram\n",
    "    return analysis != \"interp\" and not analysis.startswith(\"num\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ala', 'subst:sg:nom:f', 'disamb']\n",
      "['mieć', 'fin:sg:ter:imperf', 'disamb']\n",
      "['kot', 'subst:sg:acc:m2', 'disamb']\n",
      "['12', 'none']\n",
      "['123', 'none']\n",
      "['.', 'none']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ala', 'subst'), ('mieć', 'fin'), ('kot', 'subst')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze(\"ala ma kota\\n\\n\\n\\n12     123.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LIST = 'files.p'\n",
    "DATA_DIR = \"/run/media/maciej/Nowy/data/json/\"\n",
    "CHOSEN_YEAR = \"2011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "judgment_types = {\n",
    "    \"I\":  \"A?C.*\",\n",
    "    \"II\": \"A?U.*\",\n",
    "    \"III\": \"A?K.*\",\n",
    "    \"IV\": \"G.*\",\n",
    "    \"V\": \"A?P.*\",\n",
    "    \"VI\": \"R.*\",\n",
    "    \"VII\": \"W.*\",\n",
    "    \"VIII\": \"Am.*\",\n",
    "}\n",
    "\n",
    "def get_judgment_type(number):\n",
    "    for key, value in judgment_types.items():\n",
    "        if re.search(value, number):\n",
    "            return key\n",
    "    print(\"Unmatched {}\".format(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:01<00:00, 56.75it/s]\n",
      "  0%|          | 0/3215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3791 judgments from common and supreme courts\n",
      "3215 of them have explanation section\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 58/3215 [02:24<2:10:53,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched II Ns 576/08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 138/3215 [05:19<1:58:49,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 6/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 230/3215 [08:29<1:50:13,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 19/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 309/3215 [14:10<2:13:17,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SDI 11/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 395/3215 [17:54<2:07:49,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 24/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 522/3215 [23:10<1:59:31,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III SO 4/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 550/3215 [24:03<1:56:34,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 22/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 551/3215 [24:04<1:56:25,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 26/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 552/3215 [24:06<1:56:17,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 27/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 553/3215 [24:06<1:56:05,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 28/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 711/3215 [30:06<1:46:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 29/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 824/3215 [34:10<1:39:09,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III SO 9/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1390/3215 [59:55<1:18:40,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SDI 26/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1451/3215 [1:03:30<1:17:13,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 53/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1549/3215 [1:06:46<1:11:49,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III SO 18/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1551/3215 [1:06:49<1:11:41,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III ZS 19/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1575/3215 [1:07:40<1:10:27,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 54/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 1576/3215 [1:07:40<1:10:23,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 55/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1696/3215 [1:12:38<1:05:03,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III ZS 21/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1740/3215 [1:14:47<1:03:24,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III SO 19/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1743/3215 [1:14:50<1:03:12,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III SZ 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1918/3215 [1:21:30<55:06,  2.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SDI 3/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1957/3215 [1:22:57<53:19,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III ZS 1/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1989/3215 [1:23:57<51:44,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III BO 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1993/3215 [1:24:04<51:33,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III SO 1/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 1994/3215 [1:24:05<51:29,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III SO 2/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 2222/3215 [1:30:54<40:37,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 3/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2352/3215 [1:35:36<35:04,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 11/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 2426/3215 [1:38:11<31:55,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III SZ 1/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 2438/3215 [1:38:30<31:23,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III ZS 3/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 2439/3215 [1:38:31<31:20,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched III ZS 4/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2610/3215 [1:44:27<24:12,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 33/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 2611/3215 [1:44:30<24:10,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 34/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 3137/3215 [2:02:27<03:02,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 40/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 3138/3215 [2:02:28<03:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SNO 42/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 3158/3215 [2:03:08<02:13,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SDI 22/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3215/3215 [2:06:11<00:00,  2.35s/it]\n"
     ]
    }
   ],
   "source": [
    "import os, json, pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import regex\n",
    "from tqdm import tqdm\n",
    "\n",
    "word_pattern = \"\\p{Letter}+\"\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    total_judgments = []\n",
    "    files = pickle.load(open(FILE_LIST, 'rb'))\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        if file.startswith(\"judgment\"):\n",
    "            file_path = os.path.join(DATA_DIR, file)\n",
    "\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                judgments = [\n",
    "                    (x[\"textContent\"], x[\"courtCases\"][0][\"caseNumber\"]) for x in data[\"items\"] \n",
    "                    if x[\"judgmentDate\"].startswith(CHOSEN_YEAR) and x[\"courtType\"] in (\"COMMON\", \"SUPREME\")\n",
    "                ]\n",
    "                \n",
    "            total_judgments += judgments\n",
    "    \n",
    "    print(\"Found {} judgments from common and supreme courts\".format(len(total_judgments)))\n",
    "    \n",
    "    judgments_with_explanations = []    \n",
    "    for judgment, _case_num in total_judgments:        \n",
    "        match = regex.search(\"uzasadnienie\", judgment, regex.IGNORECASE)        \n",
    "        if match:\n",
    "            judgments_with_explanations.append((judgment[match.end():], _case_num))\n",
    "            \n",
    "    print(\"{} of them have explanation section\".format(len(judgments_with_explanations)))\n",
    "    \n",
    "    analyzed_judgments = defaultdict(lambda: [])\n",
    "    raw_judgments = defaultdict(lambda: [])\n",
    "    \n",
    "    for judgment, case_number in tqdm(judgments_with_explanations):\n",
    "        \n",
    "        judgment = regex.sub(\"<.*?>\", \"\", judgment)\n",
    "        judgment = regex.sub(\"-\\n(\\p{Letter}+)\", r\"\\1\", judgment)\n",
    "        judgment = judgment.lower()\n",
    "\n",
    "        judgment_type = get_judgment_type(case_number)\n",
    "\n",
    "        raw_judgments[judgment_type].append(judgment)\n",
    "        analyzed_judgments[judgment_type].append(analyze(judgment))\n",
    "    \n",
    "    return analyzed_judgments, raw_judgments\n",
    "\n",
    "analyzed_judgments, raw_judgments = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(list(analyzed_judgments.items()), open(\"analyzed_judgments.p\", \"wb\"))\n",
    "# pickle.dump(list(raw_judgments.items()), open(\"raw_judgments.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "analyzed_judgments = pickle.load(open('analyzed_judgments.p', 'rb'))\n",
    "raw_judgments = pickle.load(open('raw_judgments.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3215"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_judgments = []\n",
    "for key, value in raw_judgments:\n",
    "    for judgment in value:\n",
    "        flat_judgments.append((key, judgment))\n",
    "len(flat_judgments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent = ['na',\n",
    " 'do',\n",
    " 'nie',\n",
    " 'art',\n",
    " 'że',\n",
    " 'przez',\n",
    " 'ust',\n",
    " 'się',\n",
    " 'dzień',\n",
    " 'jest',\n",
    " 'oraz',\n",
    " 'ustawa',\n",
    " 'od',\n",
    " 'postępowanie',\n",
    " 'nr',\n",
    " 'sąd',\n",
    " 'punkt',\n",
    " 'za',\n",
    " 'tym',\n",
    " 'to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4623718\n"
     ]
    }
   ],
   "source": [
    "polish_dictionary = {}\n",
    "with open(\"dict.p\") as f:\n",
    "    for line in f.readlines():\n",
    "        base_word, flex_form, meta = line.split(\";\")\n",
    "        polish_dictionary[flex_form.lower()] = base_word\n",
    "        \n",
    "print(len(polish_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3215/3215 [00:07<00:00, 413.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import regex\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "word_pattern = \"\\p{Letter}+\"\n",
    "\n",
    "filtered_judgments = defaultdict(lambda: [])\n",
    "for key, judgment in tqdm(flat_judgments):\n",
    "    filtered_judgment = []\n",
    "    \n",
    "    for match in regex.finditer(word_pattern, judgment):\n",
    "        [word] = match.captures()\n",
    "        \n",
    "        analyzed_word = polish_dictionary.get(word, word)\n",
    "        if not (analyzed_word in most_frequent):\n",
    "            filtered_judgment.append(word)\n",
    "    filtered_judgments[key].append(filtered_judgment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zaskarżyć', 'postanowienie', 'sad']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzed_filtered = [\n",
    "    (key, [[unigram[0] for unigram in judgment if is_valid_unigram(unigram)] for judgment in judgments]) \n",
    "    for key, judgments in analyzed_judgments\n",
    "]\n",
    "\n",
    "analyzed_filtered[0][1][0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 2100), ('III', 510), ('II', 371), ('V', 132), ('VIII', 33), ('IV', 8), ('VII', 25)]\n",
      "[('I', 2100), ('III', 510), ('II', 371), ('V', 132), ('VIII', 33), ('IV', 8), ('VII', 25)]\n"
     ]
    }
   ],
   "source": [
    "def get_dataset(judgments):\n",
    "    analyzed_dict = dict(judgments)\n",
    "    del analyzed_dict[None]\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for judgment_type, judgments in analyzed_dict.items():\n",
    "#         print(len(judgments))\n",
    "        for judgment in judgments:\n",
    "            X.append(judgment)\n",
    "            Y.append(judgment_type)\n",
    "            \n",
    "    print([(x, len(y)) for x, y in analyzed_dict.items()])\n",
    "    return X, Y\n",
    "        \n",
    "X_tagged, Y_tagged = get_dataset(analyzed_filtered)\n",
    "X_untagged, Y_untagged = get_dataset(filtered_judgments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3179 3179 3179 3179\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(X_tagged), \n",
    "    len(Y_tagged), \n",
    "    len(X_untagged), \n",
    "    len(Y_untagged),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def shuffle_and_split_dataset(X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = [], [], [], []\n",
    "\n",
    "    dataset_dict = defaultdict(list)\n",
    "\n",
    "    for x,y in zip(X, Y):\n",
    "        dataset_dict[y].append(x)\n",
    "    \n",
    "    for judgment_type, judgment_list in dataset_dict.items():\n",
    "        random.shuffle(judgment_list)\n",
    "        pivot = len(judgment_list) * 3 // 4\n",
    "    \n",
    "        X_train_loc = judgment_list[:pivot]\n",
    "        X_test_loc = judgment_list[pivot:]\n",
    "        \n",
    "        X_train += X_train_loc\n",
    "        X_test += X_test_loc\n",
    "        Y_train += [judgment_type for _ in range(len(X_train_loc))]\n",
    "        Y_test += [judgment_type for _ in range(len(X_test_loc))]\n",
    "            \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "labels = ['I', 'II', 'III', 'IV', 'V', 'VII', 'VIII']\n",
    "report_message = \"\"\"\n",
    "Accuracy score: \n",
    "{}\n",
    "Classification report: \n",
    "{}\n",
    "Micro report: \n",
    "{}\n",
    "Macro report: \n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train(X, Y, clf_params):\n",
    "    X_train, X_test, Y_train, Y_test = shuffle_and_split_dataset(X, Y)\n",
    "\n",
    "    Y_train = np.array([labels.index(category) for category in Y_train])\n",
    "    Y_test = np.array([labels.index(category) for category in Y_test])\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        tokenizer=lambda x: x,\n",
    "        lowercase=False\n",
    "    )\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    clf = svm.SVC(**clf_params)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "\n",
    "    print(\n",
    "        report_message.format(\n",
    "            accuracy_score(Y_test, Y_predicted),\n",
    "            classification_report(Y_test, Y_predicted, target_names=labels),\n",
    "            precision_recall_fscore_support(Y_test, Y_predicted, average='micro'),\n",
    "            precision_recall_fscore_support(Y_test, Y_predicted, average='macro')\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score: \n",
      "0.9498117942283564\n",
      "Classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          I       0.96      0.99      0.97       525\n",
      "         II       0.94      0.91      0.93        93\n",
      "        III       0.94      0.91      0.92       128\n",
      "         IV       1.00      0.50      0.67         2\n",
      "          V       0.86      0.58      0.69        33\n",
      "        VII       1.00      1.00      1.00         7\n",
      "       VIII       1.00      0.78      0.88         9\n",
      "\n",
      "avg / total       0.95      0.95      0.95       797\n",
      "\n",
      "Micro report: \n",
      "(0.9498117942283564, 0.9498117942283564, 0.9498117942283564, None)\n",
      "Macro report: \n",
      "(0.9571491586904431, 0.8105653286485659, 0.8657529239544747, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': 100, \n",
    "    'gamma': 1e-2, \n",
    "    'kernel': 'linear',\n",
    "}\n",
    "train(X_tagged, Y_tagged, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score: \n",
      "0.9535759096612296\n",
      "Classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          I       0.96      0.99      0.97       525\n",
      "         II       0.98      0.89      0.93        93\n",
      "        III       0.92      0.95      0.93       128\n",
      "         IV       1.00      0.50      0.67         2\n",
      "          V       0.92      0.70      0.79        33\n",
      "        VII       1.00      0.71      0.83         7\n",
      "       VIII       0.80      0.89      0.84         9\n",
      "\n",
      "avg / total       0.95      0.95      0.95       797\n",
      "\n",
      "Micro report: \n",
      "(0.9535759096612296, 0.9535759096612296, 0.9535759096612296, None)\n",
      "Macro report: \n",
      "(0.9395127285897729, 0.8046298692986481, 0.8538941528037963, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': 100, \n",
    "    'gamma': 1e-2, \n",
    "    'kernel': 'linear',\n",
    "}\n",
    "train(X_untagged, Y_untagged, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
